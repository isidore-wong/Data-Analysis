## 假设检验

### 1.1 基本概念

假设检验问题时统计推断中的一类重要问题，在总体的分布函数完全未知或只知其形式，不知其参数的情况，为了推断总体的某些未知特性，提出某些关于总体的假设，这类问题被称为假设检验。

### 1.2 基本步骤

一个假设检验问题可以分为5步，无论细节如果变化，都一定会遵循这5个步骤。

1. 陈述研究假设，包含原假设（null hypothesis）和备择假设（alternate hypothesis）
2. 为验证假设收集数据
3. 构造合适的统计测试量并测试
4. 决定是接受还是拒绝原假设
5. 展示结论

步骤1：

通常来说，我们会把原假设的描述写成变量之间不存在某种差异，或不存在某种关联，备择假设则为存在某种差异或关联。

例如，原假设：男人和女人的平均身高没有差别， 备择假设男人和女人的平均身高存在显著差别。

步骤2:

为了统计检验的结果真实可靠，需要根据实际的假设命题从总体中抽取样本，要求抽样的数据要具有代表性，例如在上述男女平均身高的命题中，抽取的样本要能覆盖到各类社会阶级，各个国家等所有可能影响到身高的因素。

步骤3：

统计检验量有很多种类，但是所有的统计检验都是基于组内方差和组间方差的比较，如果组间方差足够大，使得不同组之间几乎没有重叠，那么统计量会反映出一个非常小的P值，意味着不同组之间的差异不可能是由偶然性导致的。

步骤4：

基于统计量的结果做出接受或拒绝原假设的判断，通常我们会以P=0.05作为临界值（单侧检验）。

步骤5：

展示结论。

### 1.3 统计量的选择

选择合适的统计量是进行假设检验的关键步骤，最常用的统计检验包括回归检验(regression test)，比较检验(comparison test)和关联检验(correlation test)三类。

**回归检验**

回归检验适用于预测变量是数值型的情况，根据预测变量的数量和结果变量的类型又分为以下几种。

|              |    预测变量    | 结果变量 |
| :----------: | :------------: | :------: |
| 简单线性回归 | 单个，连续数值 | 连续数值 |
| 多重线性回归 | 多个，连续数值 | 连续数值 |
| Logistic回归 |    连续数值    | 二元类别 |

**比较检验**

比较检验适用于预测变量是类别型，结果变量是数值型的情况，根据预测变量的分组数量和结果变量的数量又可以分为以下几种。

|                    |     预测变量     |       结果变量       |
| :----------------: | :--------------: | :------------------: |
|   Paired t-test    |    两组，类别    | 组来自同一总体，数值 |
| Independent t-test |    两组，类别    | 组来自不同总体，数值 |
|       ANOVA        | 两组及以上，类别 |      单个，数值      |
|       MANOVA       | 两组及以上，类别 |   两个及以上，数值   |

**关联检验**

关联检验常用的只有卡方检验一种，适用于预测变量和结果变量均为类别型的情况。

**非参数检验**

此外，由于一般来说上述参数检验都需满足一些前提条件，样本之间独立，不同组的组内方差近似和数据满足正态性，所以当这些条件不满足的时候，我们可以尝试用非参数检验来代替参数检验。

|        非参数检验         | 用于替代的参数检验 |
| :-----------------------: | :----------------: |
|         Spearman          |   回归和关联检验   |
|         Sign test         |       T-test       |
|      Kruskal–Wallis       |       ANOVA        |
|          ANOSIM           |       MANOVA       |
|  Wilcoxon Rank-Sum test   | Independent t-test |
| Wilcoxon Signed-rank test |   Paired t-test    |
|                           |                    |

### 1.4 两类错误

事实上当我们进行假设检验的过程中是存在犯错误的可能的，并且理论上来说错误是无法完全避免的。根据定义，错误分为两类，一类错误（type I error）和二类错误（type II error）。

- 一类错误：拒绝真的原假设

- 二类错误：接受错误的原假设

  

一类错误可以通过α值来控制，在假设检验中选择的 α（显著性水平）对一类错误有着直接影响。α可以认为是我们犯一类错误的最大可能性。以95%的置信水平为例，a=0.05，这意味着我们拒绝一个真的原假设的可能性是5%。从长期来看，每做20次假设检验会有一次犯一类错误的事件发生。

二类错误通常是由小样本或高样本方差导致的，二类错误的概率可以用β来表示，和一类错误不同的是，此类错误是不能通过设置一个错误率来直接控制的。对于二类错误，可以从功效的角度来估计，首先进行功效分析（power analysis）计算出功效值1-β，进而得到二类错误的估计值β。

一般来说这两类错误是无法同时降低的，在降低犯一类错误的前提下会增加犯二类错误的可能性，在实际案例中如何平衡这两类错误取决于我们更能接受一类错误还是二类错误。

### 1.5 Python代码实战

本节通过一些例子来讲解如何使用python进行假设检验。

#### 1.5.1 正态检验

Shapiro-Wilk Test是一种经典的正态检验方法。

H0: 样本总体服从正态分布

H1: 样本总体不服从正态分布 

```python
import numpy as np
from scipy.stats import shapiro
data_nonnormal = np.random.exponential(size=100)
data_normal = np.random.normal(size=100)

def normal_judge(data):
	stat, p = shapiro(data)
	if p > 0.05:
		return 'stat={:.3f}, p = {:.3f}, probably gaussian'.format(stat,p)
	else:
		return 'stat={:.3f}, p = {:.3f}, probably not gaussian'.format(stat,p)

# output
normal_judge(data_nonnormal)
# 'stat=0.850, p = 0.000, probably not gaussian'
normal_judge(data_normal)
# 'stat=0.987, p = 0.415, probably gaussian'
```

#### 1.5.2 卡方检验

目的：检验两组类别变量是相关的还是独立的

H0: 两个样本是独立的

H1: 两组样本不是独立的

```python
from scipy.stats import chi2_contingency
table = [[10, 20, 30],[6,  9,  17]]
stat, p, dof, expected = chi2_contingency(table)
print('stat=%.3f, p=%.3f' % (stat, p))
if p > 0.05:
	print('Probably independent')
else:
	print('Probably dependent')

 # output
#stat=0.272, p=0.873
#Probably independent
```

#### 1.5.3 T-test

目的：检验两个独立样本集的均值是否具有显著差异

H0: 均值是相等的

H1: 均值是不等的

```python
from scipy.stats import ttest_ind
import numpy as np
data1 = np.random.normal(size=10)
data2 = np.random.normal(size=10)
stat, p = ttest_ind(data1, data2)
print('stat=%.3f, p=%.3f' % (stat, p))
if p > 0.05:
	print('Probably the same distribution')
else:
	print('Probably different distributions')
    
# output
# stat=-1.382, p=0.184
# Probably the same distribution
```

#### 1.5.4 ANOVA

目的：与t-test类似，ANOVA可以检验两组及以上独立样本集的均值是否具有显著差异

H0: 均值是相等的

H1: 均值是不等的

```python
from scipy.stats import f_oneway
import numpy as np
data1 = np.random.normal(size=10)
data2 = np.random.normal(size=10)
data3 = np.random.normal(size=10)
stat, p = f_oneway(data1, data2, data3)
print('stat=%.3f, p=%.3f' % (stat, p))
if p > 0.05:
	print('Probably the same distribution')
else:
	print('Probably different distributions')
 
# output
# stat=0.189, p=0.829
# Probably the same distribution
```

#### 3.5.5 Mann-Whitney U Test

目的：检验两个样本集的分布是否相同

H0: 两个样本集的分布相同

H1: 两个样本集的分布不同

```python
from scipy.stats import mannwhitneyu
data1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]
data2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]
stat, p = mannwhitneyu(data1, data2)
print('stat=%.3f, p=%.3f' % (stat, p))
if p > 0.05:
	print('Probably the same distribution')
else:
	print('Probably different distributions')

# output
# stat=40.000, p=0.236
# Probably the same distribution
```

## 参考资料

1. Ross S . 概率论基础教程[M]. 人民邮电出版社, 2007.
2. 盛骤, 谢式千, 潘承毅, 等. 概率论与数理统计 (第四版)[J]. 2008.
3. [17 Statistical Hypothesis Tests in Python](https://machinelearningmastery.com/statistical-hypothesis-tests-in-python-cheat-sheet/)
4. [Scipy](https://www.scipy.org/)
5. [The Difference Between Type I and Type II Errors in Hypothesis Testing
](https://www.thoughtco.com/difference-between-type-i-and-type-ii-errors-3126414)