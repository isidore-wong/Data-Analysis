### 随机变量
---

#### 1. 随机变量概念

- **随机变量**

设 $E$ 是随机试验，$\Omega$ 是样本空间，如果对于每一个 $\omega \in \Omega $ 。都有一个确定的实数 $X(\omega)$ 与之对应，若对于任意实 $x \in R $ , 有 $ {\omega ：X(\omega) < x } \in F$ ，则称 $\Omega $ 上的单值实函数 $X(\omega)$ 为一个随机变量。

从定义可知随机变量是定义在样本空间 $\Omega$ 上，取值在实数域上的函数。由于它的自变量是随机试验的结果，而随机试验结果的出现具有随机性，因此，随机变量的取值也具有一定的随机性。这是随机变量与普通函数的不同之处。

随机变量的本质是一个映射，是关于随机试验的样本空间的映射，它的随机性体现在相当于映射自变量集合的随机试验的样本空间，而非映射法则。映射法则是确定的。

描述一个随机变量，不仅要说明它能够取那些值，而且还要关心它取这些值的概率。因此，随机变量的分布函数来表示其取值的概率

- **随机变量的分布函数**

 设 $X$ 是一个随机变量，对任意的实数 $x$ ，令 $$ F(x) = P { X<=x} ,x \in (- \infty ,+ \infty) $$ 
```math
F(x) = P \{ X<=x\}, x \in (- \infty ,+ \infty)
```
则称 $F(x)$ 为随机变量 $x$ 的分布函数，也称为概率累积函数。

直观上看，分布函数 $F(x)$ 是一个定义在 $(- \infty, + \infty)$ 上的实值函数， $F(x)$在点 $x$ 处取值为随机变量 $X$ 落在区间 $(- \infty, + x]$上的概率 。分布函数（概率累积函数）很好理解，就是在一个区间范围内概率函数的累加。这个区间就是负无穷到当前节点。


#### 2. 离散型随机变量

如果随机变量$X$的全部可能取值只有有限多个或可列无穷多个，则称 $X$ 为离散型随机变量。掷骰子的结果就是离散型随机变量。

对于离散型随机变量 $X$ 可能取值为 $x_k$的概率为：
$$ P { X =x_k } =p_k,k=1,2,... $$ 
```math
P \{ X =x_k \} =p_k, \  \ k=1,2,... 
```
则称上式为离散型随机变量 $X$ 的分布律。

<table><tr><td bgcolor=#FF00FF>我们可以用下表来表示分布律：</td></tr></table>

  | **$X$**   | $x_1$ | $x_2$ | ...... | $x_n$ | ...... |
  | --------- | :---: | ----- | ------ | ----- | ------ |
  | **$p_k$** | $p_1$ | $p_2$ | ...... | $p_n$ | ...... |
  
离散型随机变量的分布函数为：
  $$
  F (x) = P \{  X<=x \} =\sum_{x_k <=x}{ P \{  X=x_k \} } = \sum_{x_k <=x}{ P_k}
  $$
  
```math
F (x) = P \{  X<=x \} =\sum_{x_k <=x}{ P \{  X=x_k \} } = \sum_{x_k <=x}{ P_k}
```

#### 3.常见的离散型分布
##### 3.1 伯努利实验，二项分布

- **定义：**

    如果一个随机试验只有两种可能的结果 $A$ 和 $\overline A$，并且$$P(A) = p，P(\overline A) =1-p=q$$

```math
P(A) = p，P(\overline A) =1-p=q
```
  其中， $0<p<1$ ，则称此试验为Bernoulli(伯努利)试验. Bernoulli试验独立重复进行n次，称为n重伯努利试验。

- eg.

  从一批产品中检验次品，在其中进行有放回抽样n次，抽到次品称为“成功”，抽到正品称为“失败“，这就是n重Bernoulli试验。

  设$$A = \{ n重伯努利试验中A出现k次\}$$
```math
A = \{ n重伯努利试验中A出现k次\}
```
  则$$P(A_k） =C^k_n p^k (1-p)^{n-k},k=0,1,2,...n.$$
```math
P(A_k） =C^k_n p^k (1-p)^{n-k}, \ \ k=0,1,2,...n.
```
  这就是著名的二项分布，常记作 $B(n，k$。

- **二项分布的分布函数：**

  若随机变量 $X$ 的分布律为：
  $$P \{ X =k \} =C^k_np^k(1-p)^{n-k},k=0,1,2,...n.$$
```math
P \{ X =k \} =C^k_np^k(1-p)^{n-k},k=0,1,2,...n.
```
  其分布函数为：$$F（x） = \sum_{k=}^{[x]} {C^k_np^k(1-p)^{n-k}},k=0,1,2,...n. $$
```math
F（x） = \sum_{k=0}^{[x]} {C^k_np^k(1-p)^{n-k}},k=0,1,2,...n. 
```
  其中， $[x]$ 表示向下取整，即不超过 $x$ 的最大整数。
  
#### 4.随机变量的数字特征
##### 4.1 数学期望

- 离散型：设离散型随机变量 $X$ 的分布律为 $P \{  X=x_i\} = p_i ,i =1，2，...，$ 
```math
P \{  X=x_i\} = p_i ,i =1，2，...，
```

若级数 $ \sum_{i} {|x_i|p_i}$ 收敛，<font color=red>（收敛指会聚于一点，向某一值靠近，相对于发散）。</font>  则称级数 $ \sum_{i} {x_ip_i}$  的和为随机变量 $X$ 的数学期望。记为 $E(X)$ ,即：$$E(X) = \sum_{i} {x_ip_i}$$
```math
E(X) = \sum_{i} {x_ip_i}
```

  - 设连续型随机变量 $X$ 的概率密度函数为 $f(x)$ ,若积分 $\int_{- \infty}^{+ \infty}{|x|f（x）}dx$ 收敛， 称积分 $\int_{- \infty}^{+ \infty}{xf（x）}dx$ 的值为随机变量 $X$ 的数学期望，记为 $E(X)$ ,即：
    $$
    E(X)=  \int_{- \infty}^{+ \infty}{xf（x）}dx 
    $$
 
```math
 E(X)=  \int_{- \infty}^{+ \infty}{xf（x）}dx 
```
$E(X)$ 又称为均值。

  数学期望代表了随机变量取值的平均值，是一个重要的数字特征。数学期望具有如下性质：
  1. 若 $c$ 是常数，则 $E(c) =c$ ;
  2. $E(aX+bY) = aE(X) +bE(Y)$ , 其中a, b为任意常数；
  3. 若 $X, Y$ 相互独立，则$E(XY) = E(X)E(Y)$ ; <font color=red>（相互独立就是没有关系，不相互影响）。</font>


##### 4.2 方差
- 设 $X$ 为随机变量，如果 $E\{[X-E(X)]^2\} $ 存在，则称 $E\{  [X-E(X)]^2\} $ 为 $X$ 的方差。记为 $Var(X)$ , 即：
$$ Var （X） =E\{[X-E(X)]^2\} $$
```math
Var （X） =E\{[X-E(X)]^2\}
```
并且称 $ \sqrt{Var(X)} $  为 $X$ 的标准差或均方差。

方差是用来描述随机变量取值相对于均值的离散程度的一个量，也是非常重要的数字特征。方差有如下性质:
1. 若 $c$ 是常数，则 $Var(c) =0$ ;
2. $Var(aX+b) = a^2E(X)  $ , 其中a, b为任意常数；
3. 若 $X, Y$ 相互独立，则$Var(X+Y) = Var(X) +Var(Y)$ 。


##### 4.3 协方差和相关系数

协方差和相关系数都是描述随机变量 $X$ 与随机变量 $Y$ 之间的线性联系程度的数字量。

- 设 $X, Y$ 为两个随机变量，称 $ E\{ [X-E(X)] [Y-E(Y)]\} $ 
```math
E\{[X-E(X)] [Y-E(Y)]\}
```
为 $X$ 和 $Y$ 的协方差，记为 $Cov(X, Y)$，即：
$$ Cov(X, Y) = E\{ [X-E(X)] [Y-E(Y)]\} $$
```math
Cov(X, Y) = E\{ [X-E(X)] [Y-E(Y)]\}
```
协方差有如下性质：
1. $Cov(X, Y) = Cov(Y, X) $ ;
 ```math
Cov(X, Y) = Cov(Y, X)
```

2. $Cov(aX+b，cY+d) =ac Cov(X，Y) $ ,其中，$a,b,c,d$ 为任意常数；
```math
Cov(aX+b，cY+d) =ac Cov(X，Y),\ \ 其中，a,b,c,d为任意常数
```

3. $Cov(X_1 + X_2，Y) = Cov(X_1，Y) + Cov(X_2，Y) $ ;
```math
Cov(X_1 + X_2，Y) = Cov(X_1，Y) + Cov(X_2，Y)
```

4. $Cov(X，Y) =E( X，Y) -E( X)E(Y) $ ;  当 $X,Y$ 相互独立时，有 $Cov(X，Y) = 0$;
```math
Cov(X，Y) =E( X，Y) -E( X)E(Y) ; \ \ 当 X,Y 相互独立时，有 Cov(X，Y) = 0
```

5. $|Cov(X，Y)| = \sqrt {Var(X)} \sqrt {Var(Y)} $ ; 
```math
|Cov(X，Y)| = \sqrt {Var(X)} \sqrt {Var(Y)};
```

6. $Cov(X，X) =Var( X) $ ;
```math
Cov(X，X) =Var( X);
```

- 当 $\sqrt {Var(X)}  >0 ，\sqrt {Var(Y)} >0$ 时，称
  $$
  \rho（X,Y） = \frac{Cov(X，Y)}{\sqrt {Var(X)} \sqrt {Var(Y)}}
  $$

```math
\rho（X,Y） = \frac{Cov(X，Y)}{\sqrt {Var(X)} \sqrt {Var(Y)}}
```
为  $X,Y$ 的相关系数，它是无纲量的量（也就是说没有单位，只是个代数值）。

- <font color=red>基本上我们都会用相关系数来衡量两个变量之间的相关程度。相关系数在-1到1之间，小于零表示负相关，大于零表示正相关。绝对值 $|\rho（X,Y）|$ 表示相关度的大小。越接近1，相关度越大。</font>